import type { BaseChatEngine, NonStreamingChatEngineParams, StreamingChatEngineParams } from "@llamaindex/core/chat-engine";
import type { LLM } from "@llamaindex/core/llms";
import { BaseMemory } from "@llamaindex/core/memory";
import { EngineResponse } from "@llamaindex/core/schema";
/**
 * SimpleChatEngine is the simplest possible chat engine. Useful for using your own custom prompts.
 */
export declare class SimpleChatEngine implements BaseChatEngine {
    memory: BaseMemory;
    llm: LLM;
    get chatHistory(): import("@llamaindex/core/llms").ChatMessage<object>[] | Promise<import("@llamaindex/core/llms").ChatMessage<object>[]>;
    constructor(init?: Partial<SimpleChatEngine>);
    chat(params: NonStreamingChatEngineParams): Promise<EngineResponse>;
    chat(params: StreamingChatEngineParams): Promise<AsyncIterable<EngineResponse>>;
    reset(): void;
}
